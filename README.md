# Pixels_to_Words_Image_Captioning_Using_CNN_and_LSTM
This project, Pixels to Words: Image Captioning Using CNN and LSTM, uses a deep learning model to generate meaningful captions for images. The model combines DenseNet201 for image feature extraction and LSTM for text generation. It is trained on the Flickr8k dataset.
